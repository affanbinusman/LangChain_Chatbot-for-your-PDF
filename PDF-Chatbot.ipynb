{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "# For pdf parsing, chunks and vectorization\n",
    "import pdfplumber\n",
    "import PyPDF4\n",
    "import re              \n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# For open source models\n",
    "from langchain.llms import HuggingFaceHub, Cohere\n",
    "\n",
    "# For converastional LLM \n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "# API Keys\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting meta data from the pdf\n",
    "\n",
    "def extract_metadata_from_pdf(file_path):\n",
    "    with open(file_path, \"rb\") as pdf_file:\n",
    "        reader = PyPDF4.PdfFileReader(pdf_file) \n",
    "        metadata = reader.getDocumentInfo()\n",
    "        return {\n",
    "            \"title\": metadata.get(\"/Title\", \"\").strip(),\n",
    "            \"author\": metadata.get(\"/Author\", \"\").strip(),\n",
    "            \"creation_date\": metadata.get(\"/CreationDate\", \"\").strip(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting individual pages from pdf\n",
    "\n",
    "def extract_pages_from_pdf(file_path):\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        pages = []\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text()\n",
    "            if text.strip():  # Check if extracted text is not empty\n",
    "                pages.append((page_num + 1, text))\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function calls for extracting meta data and individual pages\n",
    "\n",
    "def parse_pdf(file_path):\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "    metadata = extract_metadata_from_pdf(file_path)\n",
    "    pages = extract_pages_from_pdf(file_path)\n",
    "\n",
    "    return pages, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning tasks\n",
    "\n",
    "# Merging hyphen words\n",
    "def merge_hyphenated_words(text):\n",
    "    return re.sub(r\"(\\w)-\\n(\\w)\", r\"\\1\\2\", text)\n",
    "\n",
    "# Adding new lines to the same string\n",
    "def fix_newlines(text):\n",
    "    return re.sub(r\"(?<!\\n)\\n(?!\\n)\", \" \", text)\n",
    "\n",
    "# Removing mulitple lines and adding them to the same string \n",
    "def remove_multiple_newlines(text):\n",
    "    return re.sub(r\"\\n{2,}\", \"\\n\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning pages and returning cleaned pages\n",
    "\n",
    "def clean_text(pages, cleaning_functions):\n",
    "    cleaned_pages = []\n",
    "    for page_num, text in pages:\n",
    "        for cleaning_function in cleaning_functions:\n",
    "            text = cleaning_function(text)\n",
    "        cleaned_pages.append((page_num, text))\n",
    "    return cleaned_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making document into smaller cunks\n",
    "\n",
    "def text_to_docs(text, metadata):\n",
    "    doc_chunks = []\n",
    "\n",
    "    for page_num, page in text:\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
    "            chunk_overlap=200,\n",
    "        )\n",
    "        chunks = text_splitter.split_text(page)\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            doc = Document(\n",
    "                page_content=chunk,\n",
    "                metadata={\n",
    "                    \"page_number\": page_num,\n",
    "                    \"chunk\": i,\n",
    "                    \"source\": f\"p{page_num}-{i}\",\n",
    "                    **metadata,\n",
    "                },\n",
    "            )\n",
    "            doc_chunks.append(doc)\n",
    "\n",
    "    return doc_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you complete the following tasks before proceeding\n",
    "    - rename \"copy.env\" file to \".env\" \n",
    "    - Add your API keys for huggingface and Cohere. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading API keys\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your PDF to \"pdfs\" folder and add the path in the \"file_path\" variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse PDF\n",
    "file_path = \"pdfs/example1.pdf\"               # Update the file path here\n",
    "raw_pages, metadata = parse_pdf(file_path)\n",
    "title = metadata['title'].split(\".\")[0]\n",
    "\n",
    "# Create text chunks\n",
    "cleaning_functions = [\n",
    "    merge_hyphenated_words,\n",
    "    fix_newlines,\n",
    "    remove_multiple_newlines,\n",
    "]\n",
    "cleaned_text_pdf = clean_text(raw_pages, cleaning_functions)\n",
    "document_chunks = text_to_docs(cleaned_text_pdf, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using embeddings from HuggingFace and saving this embeddings file\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    document_chunks,\n",
    "    embeddings,\n",
    "    collection_name=\"pdf-chat\",\n",
    "    persist_directory=\"chroma\",\n",
    ")\n",
    "\n",
    "# Save DB locally\n",
    "vector_store.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run either one of the two blocks. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model using HuggingFace\n",
    "    - You can choose any LLM from hugging face.\n",
    "    - google/flan-t5 and its variants or gpt2 are one of many models available\n",
    "    - If you update the model, some parameters may need some modification in arugments \n",
    "\n",
    "In my testing, Cohere's model has given consistent performance with reliable results. You may also use OpenAI's LLM by modifying the code for GPT4 / ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for loading parameters of the models from hugging face.\n",
    "\n",
    "def make_chain():\n",
    "    # Loading model parms\n",
    "    model = HuggingFaceHub(\n",
    "        repo_id=\"google/flan-t5-xxl\", # or you can choose \"gpt2\" etc\n",
    "        verbose=False, \n",
    "        model_kwargs={\"temperature\":1, \"max_length\":100}\n",
    "    )\n",
    "    \n",
    "    # Defining LLM template\n",
    "    template = \"Answer the following question using information from the document titled\" + str(title) + \\\n",
    "        \"Question: {question} \\\n",
    "        Answer: Let's think step by step and provide accurate answer(s).\"\n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "    # Utilizing the stored vector representation\n",
    "    vector_store = Chroma(\n",
    "        collection_name=\"pdf-chat\",\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=\"chroma\",\n",
    "    )\n",
    "\n",
    "    # call to model with all parameters defined above\n",
    "    return ConversationalRetrievalChain.from_llm(\n",
    "        llm=model,\n",
    "        condense_question_prompt=prompt,\n",
    "        retriever=vector_store.as_retriever(),\n",
    "        return_source_documents=True,\n",
    "        verbose=False\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model using Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chain():\n",
    "    # Loading model parms\n",
    "    model = Cohere(\n",
    "        verbose=True, \n",
    "        temperature= 0, \n",
    "        max_tokens= 200\n",
    "    )\n",
    "\n",
    "    # Defining LLM template\n",
    "    template = \"Answer the following question using information from the document titled\" + str(title) + \\\n",
    "        \"Question: {question} \\\n",
    "        Answer: Let's think step by step and provide accurate answer(s).\"\n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "    \n",
    "    # Utilizing the stored vector representation\n",
    "    vector_store = Chroma(\n",
    "        collection_name=\"pdf-chat\",\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=\"chroma\",\n",
    "    )\n",
    "\n",
    "    # call to model with all parameters defined above\n",
    "    return ConversationalRetrievalChain.from_llm(\n",
    "        llm=model,\n",
    "        condense_question_prompt=prompt,\n",
    "        retriever=vector_store.as_retriever(),\n",
    "        return_source_documents=True,\n",
    "        verbose=False,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the section below (question templates available below this block). Enter exit or quit to end the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = make_chain()\n",
    "chat_history = []\n",
    "vectordbkwargs = {\"search_distance\": 0.9}\n",
    "\n",
    "while True:\n",
    "    question = input(\"Question: \")\n",
    "\n",
    "    print(question)\n",
    "    if question == \"quit\" or question == \"exit\":\n",
    "        print(\"Ending session\")\n",
    "        break\n",
    "\n",
    "    # Running similarity search to check sources of identified parts in the document\n",
    "    simSearch = vector_store.similarity_search(query=question)\n",
    "    print(\"\\nSimilarity Search:\\n{}\".format(simSearch))\n",
    "    simSearchScore = vector_store.similarity_search_with_score(query=question)\n",
    "    print(print(\"Similarity Search Score:\\n{}\\n\".format(simSearchScore[-1][-1])))\n",
    "\n",
    "    # Generate answer\n",
    "    response = chain({\"question\": question, \"chat_history\": chat_history, \"vectordbkwargs\": vectordbkwargs})\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Retrieve answer\n",
    "    answer = response[\"answer\"]\n",
    "    source = response[\"source_documents\"]\n",
    "    chat_history.append(HumanMessage(content=question))\n",
    "    chat_history.append(AIMessage(content=answer))\n",
    "\n",
    "    print(f\"Question: {question}\\nAnswer: {answer}\\n\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "List some classes from the Mechanical & Aerospace Engineering Concentration for the Robotics graduate program\n",
    "Is there a GRE waiver for application of Robotics program at Arizona State University\n",
    "What is the email address of School of Electrical, Computer, and Energy Engineering department at Arizona State University\n",
    "The Graduate Student Handbook for Robotics progam is intended for which academic year?\n",
    "Give an overview of the Robotics & Autonomous Systems program\n",
    "Can Artificial Intelligence Concentration students opt for portfolio option?\n",
    "What's the difference between Curricular Practical Training and Optional Practical Training\n",
    "What is the GPA requirement for the electrical engineering program?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard-coded examples\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"Is there a GRE waiver for application of Robotics program at Arizona State University\",\n",
    "        \"answer\": \"Yes\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the email address of School of Electrical, Computer, and Energy Engineering department at Arizona State University\",\n",
    "        \"answer\": \"eceegrad@asu.edu\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Can Artificial Intelligence Concentration students opt for portfolio option?\",\n",
    "        \"answer\": \"Yes\"\n",
    "    } ,\n",
    "    {\n",
    "        \"query\": \"The Graduate Student Handbook for Robotics progam is intended for which academic year?\",\n",
    "        \"answer\": \"2023-2024 Academic year\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"List some classes from the Mechanical & Aerospace Engineering Concentration for the Robotics graduate program\",\n",
    "        \"answer\": \"MAE 502 Partial Differential Equations, MAE 503 Finite Elements in Engineering, MAE 507 Fundamentals of Control and Optimization, MAE 508 Digital Control: Design and Implementation, MAE 509 LMI Methods in Optimal and Robust Control, MAE 510 Dynamics and Vibrations, MAE 514 Vibration Analysis, MAE 520 Stress Analysis, MAE 521 Structural Optimization, MAE 542 Design Geometry and Kinematics, MAE 548 Prob Methods for Eng Des/Analy, MAE 566 Rotary-Wing Aerodynamics, MAE 598 Bio-Inspired Robots, MAE 598 Multi-Robot Systems, MAE 598 Quantum Mech Eng: SW and HW of Quantum Computers, EGR 546 Robotic Systems- II, IEE 576 Network Optimization and Algorithms\"\n",
    "    }\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
